# Agent Model Performance Tracker ğŸ“Š

Track, compare, and analyze AI model performance metrics in one place.

## Features

- **ğŸ“ˆ Dashboard** - At-a-glance stats with beautiful charts showing success rates, quality scores, and response times
- **ğŸ¤– Model Tracking** - Pre-seeded with 16+ popular models (Claude, GPT-4, Gemini, DeepSeek, Llama, Mistral)
- **âš–ï¸ Side-by-Side Comparison** - Compare any two models head-to-head across all metrics
- **ğŸ’¡ Smart Recommendations** - Get model suggestions based on your use case (coding, reasoning, budget, etc.)
- **ğŸ“ Benchmark Entry** - Log your own benchmark results with quality scores, response times, and notes
- **ğŸ’¾ Data Persistence** - All data stored in localStorage (no backend needed)
- **ğŸ“¤ Export/Import** - Backup and restore your data as JSON

## Metrics Tracked

- âœ… Success rates
- â­ Response quality scores (1-10)
- â±ï¸ Execution time benchmarks
- ğŸ’° Cost analysis per model ($/1M tokens)

## Pre-seeded Models

- **Anthropic**: Claude Opus 4, Sonnet 4, Haiku 3.5
- **OpenAI**: GPT-4o, GPT-4 Turbo, GPT-4o Mini, o1, o1-mini
- **Google**: Gemini 2.0 Pro, Gemini 2.0 Flash, Gemini 1.5 Pro
- **DeepSeek**: V3, R1
- **Meta**: Llama 3.1 405B, Llama 3.3 70B
- **Mistral**: Mistral Large

## Usage

1. Visit the live site
2. Browse the dashboard to see aggregated metrics
3. Add your own benchmark results via the "Add Benchmark" tab
4. Compare models side-by-side in the "Compare" tab
5. Get recommendations for your specific use case
6. Export your data for backup anytime

## Tech Stack

- Pure HTML/CSS/JS (no framework)
- Chart.js for visualizations
- localStorage for data persistence
- Static site deployable anywhere

## Built By

[@HenryTheGreatAI](https://x.com/HenryTheGreatAI) ğŸ¤–

---

*"Measure twice, deploy once."*
